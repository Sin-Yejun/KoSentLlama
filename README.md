# KoSentLlama

## 📌 Llama 3.1 8B, 한국어 대화에 약하다.

최근 Llama 3.1 8B 모델을 테스트해본 결과, **한국어 대화에서 문맥이 맞지 않는 답변을 하는 경우가 많았다.** 🤔  

특히, 감성적인 대화에서 어색한 표현이 종종 등장하여 자연스러운 대화를 이어가기 어려웠음.
​
그래서 **"감성대화 말뭉치"** 데이터를 학습시켜, 보다 자연스럽고 문맥에 맞는 대화를 생성할 수 있도록 개선해보았다! 🚀


## 📂 사용한 데이터셋
​
📌 **데이터셋 이름**: 감성대화 말뭉치  

📌 **출처**: [AI Hub 감성대화 말뭉치](https://www.aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&dataSetSn=86)  

📌 **설명**:
​
-   약 **5만 건**의 대화 데이터 포함 💬
-   사람과 시스템의 응답이 기록되어 있음 📝

## 🛠️ 전처리 과정 (src/data_preprocess.ipynb)

### 1️⃣ 데이터 파일 구조 변경
- 먼저 데이터를 CSV 파일로 변환하고, 기존 파일 구조를 아래와 같이 변경함.
  
  - db/emotional_data/train/train.CSV
  - db/emotional_data/test/test.CSV
- 훈련 데이터(`train.CSV`)와 테스트 데이터(`test.CSV`)를 분리하여 저장.

---

### 2️⃣ CSV 파일을 JSONL 형태로 변환
#### 🔹 **CSV → JSONL 변환 과정**
1. **CSV 파일 로드:**  
 - `pandas`를 사용하여 CSV 파일을 불러오며, 한글 인코딩 문제를 해결하기 위해 `cp949` 인코딩 사용.  
 - 데이터 프레임(`df_train`, `df_test`)으로 변환.

2. **JSONL 형식 변환:**  
 - JSONL 변환을 위한 리스트(`jsonl_data`) 생성.  
 - 대화 데이터를 시스템 메시지를 포함한 구조로 변환.  
 - `NaN` 값(빈 값)을 방지하기 위해 문자열 변환 후 `.strip()` 처리.

3. **데이터 저장:**  
 - `train.jsonl` 및 `test.jsonl` 파일로 변환된 데이터를 저장.  
 - 변환된 JSONL 파일에는 다음과 같은 구조를 가짐.  

#### 🔹 **JSONL 데이터 예시**
```json
{
"messages": [
  {"role": "system", "content": "당신은 감정을 공감해주는 챗봇입니다."},
  {"role": "user", "content": "오늘 너무 힘들었어..."},
  {"role": "assistant", "content": "많이 힘드셨겠어요. 어떤 일이 있었나요?"},
  {"role": "user", "content": "회사에서 실수를 했는데, 상사가 너무 심하게 혼냈어."},
  {"role": "assistant", "content": "정말 속상하셨겠어요. 실수는 누구나 할 수 있는 거니까 너무 자책하지 마세요."}
]
}
```

## **🔬 Finetuning 과정** (src/finetune_model.ipynb)
​
**1. 첫번째 시도 (로컬에서 돌리기)**
​
**로컬 GPU: RTX 3060 Ti (VRAM 8GB)**

=> 학습시간이 약 21시간이 걸리고, GPU가 버티질 못해 Colab에서 자원을 할당받기로 결정했다.
****🚫 실패**** 

**2. 두번째 시도 (Colab에서 무료 T4 GPU 할당)**  

=> GPU 할당량이 모자라서, 9.99 달러를 지불하기로 결정했다.
****🚫 실패**** 

**3. 세번째 시도 (Colab에서 유로 A100 GPU 할당, 배치사이즈 8)**

=> 학습시간 약 54분만에 학습이 완료 되었다!
****✅ 성공****


## 📊 파인튜닝 평가 - TensorBoard를 이용해 정확도, 손실, 학습률 시각화

### 종합평가

-   **성공 여부**: 3200스텝(1 에포크)을 약 54분 만에 완료했으며, 손실 감소와 정확도 향상은 학습이 잘 진행되었음을 보여줍니다. 평균 손실 1.4135과 토큰 정확도 0.6552는 초기 미세 조정 결과로 만족할 만합니다.

#### 1\. 손실 (Training Loss)

-   **그래프 분석:** 손실 곡선(train/loss)은 0 스텝에서 약 1.6 이상으로 시작해 3227스텝(1epoch 완료)에서 약 1.41 으로 수렴했습니다. 초기에는 급격히 감소하다가 중반 이후에는 완만한 감소 추세를 보이며 안정화되었습니다.
-   **의미:** 손실이 감소했다는 것은 모델이 훈련 데이터를 점점 더 잘 학습하고 있음을 나타냅니다. 약 1.41 수준의 손실은 감정 대화 태스크에서 모델이 적절히 적응했음을 시사하지만, 실제 성능(예: 감정 공감 품질)은 검증 데이터로 평가해야 합니다.
-   **해석:** 손실 감소가 부드럽게 이루어졌으므로 과적합 없이 학습이 잘 진행된 것으로 보입니다. 그러나 더 낮은 손실(예: 1.3 이하)을 목표로 한다면 에포크를 추가하거나 학습률을 조정할 수 있습니다.

#### 2\. 토큰 정확도 (Mean Token Accuracy)

-   **그래프 분석:** 토큰 정확도(train/mean\_token\_accuracy)는 0 스텝에서 약 0.62로 시작해 3227 스텝에서 약 0.655로 증가했습니다. 초기에는 변동이 컸으나, 중반 이후에는 안정적인 상승세를 보이며 약 0.655 수준에서 수렴했습니다.
-   **의미:** 토큰 정확도는 모델이 예측한 토큰이 실제 레이블과 얼마나 일치하는지를 나타냅니다. 0.655는 모든 토큰의 65%를 정확히 예측했음을 의미하며, 감정 대화 데이터의 복잡성을 고려하면 괜찮은 수준입니다. 하지만 대화 생성 모델에서는 정확도만으로 성능을 판단하기 어렵습니다.
-   **해석:** 정확도가 0.65로 비교적 낮게 수렴한 것은 모델이 아직 학습 데이터에 완전히 적응하지 못했을 수 있음을 시사합니다.

#### 3\. 학습률 (Learning Rate)

-   **그래프 분석:** 학습률(train/learning\_rate)은 0 스텝에서 약 2e-4(0.0002)로 시작해 3227 스텝에서 0으로 수렴했습니다. cosine 스케줄러에 따라 부드럽게 감소하는 곡선을 그리며, 중반 이후에는 급격히 줄어드는 경향을 보였습니다.
-   **의미:** 학습률이 점진적으로 감소하며 모델이 초기에는 크게 업데이트되고, 후반에는 미세 조정을 한다는 것을 나타냅니다. 이는 과적합을 방지하고 수렴을 돕는 일반적인 전략입니다.
-   **해석:** 학습률이 적절히 조정되어 손실 감소와 정확도 증가에 기여한 것으로 보입니다. 그러나 마지막 단계에서 너무 빠르게 0에 도달했다면, 더 긴 학습이나 다른 스케줄러(예: linear)를 고려할 수 있습니다.

---
## 📊 BLEU 점수 & 코사인 유사도 개선 분석 (src/test.ipynb)

샘플 약 18000개에 대한 답변을 평가하였습니다.

| 모델 | 평가 수행 시간 | BELU 점수 | 코사인 유사도 |
| --- | --- | --- | --- |
| Llama 3.1 8B **기본 모델** | 1시간 39분 | **0.0075** | **0.3891** |
| 한국어 감성 말뭉치로 학습된   **Fine-tuning 모델** | 2시간 25분 | **0.0173** | **0.4741** |


### 1. BLEU 점수 개선 분석  
BLEU(Bilingual Evaluation Understudy) 점수는 기계 번역 및 텍스트 생성 품질을 평가하는 지표로, **0~1** 사이의 값을 가짐.  
값이 높을수록 참조 텍스트와 유사한 텍스트를 생성했다고 평가할 수 있음.  

#### 📈 미세 조정 전후 변화  
**0.0075 → 0.0173**  

#### 🔍 해석  
- BLEU 점수가 **약 130.67% 증가** (**약 2.3배 개선**).  
- 하지만 여전히 낮은 편(**0.0173**).  
- 일반적으로 **0.3~0.5 이상**이 되어야 사람이 보기에도 좋은 품질로 간주됨.  
- **➡ 결론:** BLEU 점수가 개선되었지만, 추가적인 개선이 필요할 가능성이 있음.  

---

### 2. 코사인 유사도 개선 분석  
코사인 유사도는 생성된 텍스트와 참조 텍스트의 의미적 유사도를 측정하는 지표로, **0~1** 사이의 값을 가짐.  
1에 가까울수록 의미적으로 더 유사함.  

#### 📈 미세 조정 전후 변화  
**0.3891 → 0.4741**  

#### 🔍 해석  
- 코사인 유사도가 **약 21.84% 증가** (**약 1.22배 개선**).  
- 의미적 일치도가 **약 8.5%포인트 증가**.  
- **0.5에 가까워지고 있어 의미적 유사도가 향상된 것으로 판단 가능**.  
- **➡ 결론:** 생성된 텍스트가 참조 텍스트와 의미적으로 더 가까워졌으며, 긍정적인 변화가 나타남.  

---

### 📌 종합적인 개선 정도  
✅ **BLEU 점수:** **130.67% 증가** (**약 2.3배 개선**)  
→ 절대값은 낮지만, 미세 조정 후 품질이 상당히 향상됨.  

✅ **코사인 유사도:** **21.84% 증가** (**약 1.22배 개선**)  
→ 의미적 유사도가 더 좋아졌으며, 0.5에 가까워지는 긍정적인 변화.  

---

### 🎯 최종 요약  
- **BLEU 점수**: 130.67% 증가 (**약 2.3배 개선**), 하지만 절대값이 낮아 추가 개선 필요.  
- **코사인 유사도**: 21.84% 증가 (**약 1.22배 개선**), 의미적 일치도가 더 나아짐.  
- **미세 조정이 모델 성능에 긍정적인 영향을 미침!**  
- 하지만 **BLEU 점수가 여전히 낮아 추가적인 개선이 필요할 수도 있음**.  
